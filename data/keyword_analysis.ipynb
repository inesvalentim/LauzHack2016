{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEM:  104\n",
      "REP:  143\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "LauzHack 2016\n",
    "\n",
    "Corentin Ferry\n",
    "InÃªs Valentim\n",
    "Sharbatanu Chatterjee\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# get the keywords extracted from the articles with the Text Analytics API (Microsoft)\n",
    "file = open('keywords_left.txt', 'r')\n",
    "keywords_left = file.read().split(',')\n",
    "file.close()\n",
    "\n",
    "file = open('keywords_right.txt', 'r')\n",
    "keywords_right = file.read().split(',')\n",
    "file.close()\n",
    "\n",
    "# pick a new article an look for the extracted keywords in it\n",
    "f = open('imm10.txt', 'r', encoding='utf8')\n",
    "text = f.read()\n",
    "f.close()\n",
    "    \n",
    "nb_matches_rep = 0\n",
    "nb_matches_dem = 0\n",
    "    \n",
    "for keyword in keywords_right:\n",
    "    nb_matches_rep += text.count(keyword)\n",
    "    \n",
    "for keyword in keywords_left:\n",
    "    nb_matches_dem += text.count(keyword)\n",
    "\n",
    "print('DEM: ', nb_matches_dem)\n",
    "print('REP: ', nb_matches_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
